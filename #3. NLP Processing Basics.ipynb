{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP PROCESSING BASICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP\n",
    "- Example Use Cases :\n",
    "    - Classifyng Eails as Spam vs Legitimate\n",
    "    - Sentiment Analysis of Text Movie Reviews\n",
    "    - Analyzing Trends from written customer feedback forms.\n",
    "    - Understanding text commands, \"Google, play this song\".\n",
    "\n",
    "- spacy faster than NLTK\n",
    "\n",
    "\n",
    "## Spacy\n",
    "- `pip3 install -U spacy`\n",
    "- `python3 -m spacy download en`\n",
    "\n",
    "spacy sudah memiliki model bahasa indonesia, hanya saja cara memanggilnya yang berbeda.\n",
    "\n",
    "- [spacy bahasa indoneisa](https://bagas.me/spacy-bahasa-indonesia.html)\n",
    "- [NLP Bahasa Indonesia](https://medium.com/@arie.pratama.s/bahasa-indonesia-open-sourced-nlp-resources-8cb394193238)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") # english core web small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x1128ffd50>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x11b876de0>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x11b7ca3d0>)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Tesla isn't    loOking into startup anymore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX ROOT\n",
      "n't PART neg\n",
      "    SPACE \n",
      "loOking VERB attr\n",
      "into ADP prep\n",
      "startup NOUN pobj\n",
      "anymore ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].pos_ # pos --> part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nsubj'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buying'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[4].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buy'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[4].lemma_ # bentuk dasar suatu kata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loOking: xxXxxxx\n",
      "VBG: verb, gerund or present participle\n"
     ]
    }
   ],
   "source": [
    "# simple part of speech\n",
    "print(doc2[4].text+': '+ doc2[4].shape_) # bentuk huruf nya\n",
    "print(doc2[4].tag_+': '+ spacy.explain(doc2[4].tag_)) # penjelasan part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is what happens to us while we are making other plans\"\n"
     ]
    }
   ],
   "source": [
    "life_quote = doc3[16:30] # kata ke-16 sampai dengan kata ke-30\n",
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u\"This is the first sentence. This another sentences. This is the last sentences.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This another sentences.\n",
      "This is the last sentences.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc4.sents: # cek setiap kalimat pada kumpulan kalimat\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start # untuk mengetahui bahwa kata tersebut merupakan kata yang pertama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy Bahasa Indonesia\n",
    "- [link](https://bagas.me/spacy-bahasa-indonesia.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    " import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('id') # load model bahasa menggunakan method blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisasi\n",
    "s = 'Galaxy Note 8, flagship terbaru dari samsung, bisa ditebus dengan harga 11 juta rupiah (cashback 1 juta)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.doc.Doc'>\n",
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "print(type(doc))\n",
    "print(type(doc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token-0 Galaxy\n",
      "token-1 Note\n",
      "token-2 8\n",
      "token-3 ,\n",
      "token-4 flagship\n",
      "token-5 terbaru\n",
      "token-6 dari\n",
      "token-7 samsung\n",
      "token-8 ,\n",
      "token-9 bisa\n",
      "token-10 ditebus\n",
      "token-11 dengan\n",
      "token-12 harga\n",
      "token-13 11\n",
      "token-14 juta\n",
      "token-15 rupiah\n",
      "token-16 (\n",
      "token-17 cashback\n",
      "token-18 1\n",
      "token-19 juta\n",
      "token-20 )\n"
     ]
    }
   ],
   "source": [
    "for i, token in enumerate(doc):\n",
    "    print(f\"token-{i} {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ini kalimat pertama.Ini kalimat kedua.dan ini kalimat terakhir.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: nlp.add_pipe(nlp.create_pipe('sentencizer')) Alternatively, add the dependency parser, or set sentence boundaries by setting doc[i].is_sent_start.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-91ba4b384c5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdoc_par\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc_par\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mdoc.pyx\u001b[0m in \u001b[0;36msents\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: nlp.add_pipe(nlp.create_pipe('sentencizer')) Alternatively, add the dependency parser, or set sentence boundaries by setting doc[i].is_sent_start."
     ]
    }
   ],
   "source": [
    "# sentences tokenization (segmentation) belum support untuk bahasa indonesia\n",
    "par = (\n",
    "'Ini kalimat pertama.'\n",
    "'Ini kalimat kedua.'\n",
    "'dan ini kalimat terakhir.'\n",
    ")\n",
    "\n",
    "print(par)\n",
    "\n",
    "doc_par = nlp(par)\n",
    "for sentence in doc_par.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['berujar', 'terdahulu', 'lain', 'pasti', 'menjawab', 'menunjuknya', 'biasa', 'selanjutnya', 'bawah', 'keadaan', 'kata', 'dimaksud', 'awalnya', 'lebih', 'menunjuk', 'setidaknya', 'ditunjuk', 'kiranya', 'anda', 'soalnya', 'saat', 'misalnya', 'termasuk', 'sebaik-baiknya', 'tanpa', 'mengibaratkan', 'merasa', 'bagaimanakah', 'keseluruhan', 'katanya', 'luar', 'sajalah', 'mengatakannya', 'memberi', 'terjadi', 'apalagi', 'dimulailah', 'umumnya', 'bertanya', 'padahal', 'kan', 'dirinya', 'ibaratnya', 'mengenai', 'diibaratkannya', 'satu', 'betulkah', 'disebut', 'belakangan', 'terdapat', 'sekali-kali', 'ingat', 'bahkan', 'semasa', 'tanyakan', 'lah', 'turut', 'seusai', 'atau', 'masalahnya', 'segera', 'rasanya', 'wong', 'sangat', 'menjelaskan', 'ingin', 'mempersoalkan', 'mendatang', 'seharusnya', 'tanya', 'berlangsung', 'pertama-tama', 'tegas', 'malahan', 'biasanya', 'lanjut', 'saya', 'meskipun', 'sebagai', 'disini', 'kamulah', 'diperkirakan', 'antar', 'sela', 'berikut', 'sebegitu', 'dimintai', 'oleh', 'kamilah', 'mengibaratkannya', 'ialah', 'lewat', 'tidak', 'adalah', 'ikut', 'bakalan', 'sekadar', 'mampu', 'siapa', 'lainnya', 'dahulu', 'sebisanya', 'dan', 'artinya', 'kapan', 'berlebihan', 'diucapkan', 'memperkirakan', 'sebab', 'bagaikan', 'serupa', 'kesampaian', 'sering', 'jawab', 'semula', 'sudahlah', 'diakhiri', 'mengatakan', 'dilihat', 'dijelaskannya', 'tanyanya', 'disebutkannya', 'saja', 'begitulah', 'dijelaskan', 'keluar', 'berturut', 'panjang', 'disinilah', 'bagaimana', 'supaya', 'mempertanyakan', 'walaupun', 'bolehlah', 'terakhir', 'menanti-nanti', 'terhadap', 'di', 'lagi', 'ibaratkan', 'berkali-kali', 'menandaskan', 'dimaksudkannya', 'dengan', 'selaku', 'lagian', 'jumlah', 'sebaliknya', 'berapalah', 'berakhirlah', 'boleh', 'memperlihatkan', 'hanya', 'apabila', 'bung', 'apakah', 'cukupkah', 'bolehkah', 'pada', 'masih', 'pun', 'semua', 'bilakah', 'bisakah', 'menyeluruh', 'andalah', 'begitupun', 'bulan', 'itukah', 'terjadinya', 'dimulai', 'bukankah', 'selama-lamanya', 'waduh', 'balik', 'harus', 'itu', 'ada', 'hari', 'mungkin', 'sedangkan', 'sesegera', 'menuju', 'seolah', 'para', 'menuturkan', 'berapa', 'maupun', 'dibuatnya', 'tepat', 'tidakkah', 'diantaranya', 'katakan', 'nantinya', 'perlukah', 'tadi', 'menegaskan', 'tunjuk', 'misal', 'bagaimanapun', 'bermaksud', 'jauh', 'sebutnya', 'jikalau', 'kurang', 'asalkan', 'memisalkan', 'kok', 'semisal', 'itulah', 'membuat', 'ujar', 'usai', 'ucap', 'jelaslah', 'tahu', 'antaranya', 'diibaratkan', 'dipersoalkan', 'justru', 'mendatangi', 'mirip', 'memihak', 'mempersiapkan', 'hal', 'jangankan', 'sebegini', 'ternyata', 'baik', 'benarkah', 'berarti', 'besar', 'harusnya', 'makin', 'sejauh', 'tentang', 'diingatkan', 'tampaknya', 'sebabnya', 'jumlahnya', 'diperlukannya', 'ujarnya', 'bisa', 'sebagaimana', 'bagian', 'perlunya', 'jadilah', 'ditanya', 'semata-mata', 'berapapun', 'berikan', 'terasa', 'bukanlah', 'tiap', 'dulu', 'tiba', 'sekiranya', 'belum', 'semaunya', 'sekitar', 'hanyalah', 'demikianlah', 'awal', 'apa', 'secara', 'asal', 'kelima', 'seluruhnya', 'pak', 'ibu', 'seluruh', 'malah', 'mempunyai', 'manalagi', 'toh', 'keseluruhannya', 'seterusnya', 'sepantasnyalah', 'masihkah', 'mulai', 'tertuju', 'ditandaskan', 'berikutnya', 'sehingga', 'semakin', 'merupakan', 'segalanya', 'jawabnya', 'tampak', 'diketahuinya', 'khususnya', 'kamu', 'padanya', 'ditunjukkan', 'memberikan', 'sangatlah', 'bertanya-tanya', 'kebetulan', 'berbagai', 'dipunyai', 'sekurang-kurangnya', 'berkata', 'nah', 'mendatangkan', 'minta', 'naik', 'sepanjang', 'sepantasnya', 'kemudian', 'merekalah', 'bahwa', 'jawaban', 'menghendaki', 'enggak', 'sekaligus', 'jika', 'sesuatu', 'terhadapnya', 'kapankah', 'daripada', 'hampir', 'ini', 'setidak-tidaknya', 'mengingatkan', 'dilakukan', 'mula', 'lanjutnya', 'bahwasanya', 'dua', 'kepada', 'sinilah', 'sesudah', 'akankah', 'belumlah', 'enggaknya', 'kami', 'menyebutkan', 'bersiap-siap', 'per', 'pukul', 'adanya', 'meyakinkan', 'mulailah', 'dari', 'sudah', 'menginginkan', 'kala', 'tentunya', 'tiga', 'dipertanyakan', 'meminta', 'menyiapkan', 'siapakah', 'pantas', 'lima', 'diberikan', 'cara', 'pihaknya', 'ibarat', 'sebetulnya', 'mendapatkan', 'sejak', 'mengucapkan', 'semampunya', 'sesudahnya', 'ataukah', 'sejumlah', 'ketika', 'persoalan', 'tetapi', 'sepihak', 'sebaik', 'menunjukkan', 'digunakan', 'bagi', 'inginkah', 'saling', 'tegasnya', 'selalu', 'dikerjakan', 'masing', 'hingga', 'berkenaan', 'yakni', 'mengira', 'kelamaan', 'tambah', 'melakukan', 'tersebutlah', 'hendaknya', 'wah', 'tandasnya', 'dini', 'katakanlah', 'karena', 'ditambahkan', 'begini', 'macam', 'meyakini', 'dong', 'sebelumnya', 'berakhirnya', 'mengerjakan', 'mereka', 'meski', 'mendapat', 'bersiap', 'tiba-tiba', 'bila', 'belakang', 'melainkan', 'kepadanya', 'adapun', 'pernah', 'rupanya', 'sedikit', 'sekadarnya', 'kita', 'begitu', 'ditanyakan', 'mengucapkannya', 'mengetahui', 'sendirinya', 'kenapa', 'entahlah', 'menjadi', 'diucapkannya', 'akulah', 'hendak', 'sebanyak', 'dekat', 'jelas', 'terlihat', 'kasus', 'sana', 'sepertinya', 'setibanya', 'rasa', 'tetap', 'betul', 'sama', 'tuturnya', 'apatah', 'tersampaikan', 'dituturkannya', 'tadinya', 'dijawab', 'ditegaskan', 'tinggi', 'soal', 'bersama-sama', 'sesaat', 'berada', 'disebutkan', 'nyaris', 'menanya', 'inikah', 'menaiki', 'mengingat', 'ia', 'seorang', 'terus', 'datang', 'demi', 'atas', 'dikira', 'ditanyai', 'lama', 'sebagian', 'sekecil', 'diinginkan', 'kalaulah', 'jadi', 'menanyakan', 'mengakhiri', 'cukuplah', 'kira-kira', 'untuk', 'memerlukan', 'sekurangnya', 'sejenak', 'diri', 'sebesar', 'setiba', 'ungkap', 'agak', 'baru', 'gunakan', 'bersama', 'menambahkan', 'sebaiknya', 'walau', 'akan', 'disampaikan', 'buat', 'lamanya', 'sedang', 'sama-sama', 'ataupun', 'inginkan', 'bermula', 'sambil', 'siap', 'punya', 'dimaksudnya', 'dikarenakan', 'pula', 'beginian', 'memastikan', 'selain', 'yaitu', 'se', 'beri', 'keinginan', 'namun', 'sewaktu', 'ke', 'terlebih', 'kinilah', 'waktu', 'semata', 'entah', 'menyampaikan', 'mengungkapkan', 'sayalah', 'ditunjuki', 'tapi', 'misalkan', 'semampu', 'sampaikan', 'hendaklah', 'diberi', 'masalah', 'segala', 'waktunya', 'terkira', 'diperlihatkan', 'tentulah', 'sekali', 'dia', 'setelah', 'kitalah', 'menurut', 'sesama', 'diperlukan', 'memulai', 'tertentu', 'mengapa', 'tutur', 'didapat', 'sementara', 'umum', 'pentingnya', 'kemungkinan', 'mempergunakan', 'diminta', 'guna', 'mana', 'sekalipun', 'apaan', 'cuma', 'jelaskan', 'seingat', 'bagai', 'demikian', 'dibuat', 'terbanyak', 'lalu', 'juga', 'seperti', 'sesuatunya', 'terdiri', 'bakal', 'kelihatan', 'sesekali', 'bukan', 'kira', 'bukannya', 'terjadilah', 'janganlah', 'sebut', 'mulanya', 'tentu', 'telah', 'diingat', 'sesampai', 'jadinya', 'perlu', 'berdatangan', 'keterlaluan', 'aku', 'sekitarnya', 'memang', 'sempat', 'kalian', 'memintakan', 'selamanya', 'bapak', 'bertutur', 'jelasnya', 'sendiri', 'semisalnya', 'setempat', 'ungkapnya', 'seseorang', 'terlalu', 'benarlah', 'kembali', 'melihat', 'seketika', 'tandas', 'haruslah', 'nanti', 'pihak', 'kalau', 'tak', 'diberikannya', 'usah', 'kecil', 'rata', 'makanya', 'suatu', 'masing-masing', 'melihatnya', 'seberapa', 'teringat', 'kapanpun', 'empat', 'diperbuatnya', 'bekerja', 'cukup', 'sebutlah', 'sedemikian', 'tempat', 'menanti', 'semacam', 'menunjuki', 'setiap', 'dikatakan', 'sudahkah', 'sebagainya', 'setinggi', 'menggunakan', 'menyatakan', 'nyatanya', 'percuma', 'mau', 'dikatakannya', 'antara', 'seperlunya', 'akhir', 'melalui', 'siapapun', 'akhirnya', 'memperbuat', 'selama', 'dimungkinkan', 'menanyai', 'manakala', 'berkehendak', 'sekalian', 'berakhir', 'ditunjuknya', 'tambahnya', 'sekarang', 'semuanya', 'banyak', 'sendirian', 'menantikan', 'dilalui', 'maka', 'sini', 'dalam', 'jangan', 'caranya', 'keduanya', 'beberapa', 'yakin', 'bermacam', 'beginilah', 'seolah-olah', 'memungkinkan', 'ditujukan', 'sampai-sampai', 'amat', 'teringat-ingat', 'olehnya', 'agaknya', 'agar', 'ucapnya', 'sebelum', 'berkeinginan', 'begitukah', 'diperbuat', 'dimisalkan', 'kedua', 'seenaknya', 'diungkapkan', 'beginikah', 'didatangkan', 'kelihatannya', 'paling', 'pertama', 'tersebut', 'diketahui', 'kini', 'tidaklah', 'berjumlah', 'menyangkut', 'sedikitnya', 'yang', 'berapakah', 'dimulainya', 'masa', 'berawal', 'pertanyakan', 'dimaksudkan', 'ingat-ingat', 'mampukah', 'sebuah', 'seringnya', 'diantara', 'mungkinkah', 'terutama', 'karenanya', 'berlalu', 'berturut-turut', 'dialah', 'amatlah', 'diakhirinya', 'sampai', 'tengah', 'penting', 'serta', 'depan', 'dipergunakan', 'kalaupun', 'pastilah', 'saatnya', 'berupa', 'pertanyaan', 'tahun', 'benar', 'dapat', 'sebenarnya', 'dituturkan', 'akhiri', 'kemungkinannya', 'secukupnya', 'semasih', 'berlainan', 'inilah', 'dipastikan', 'bermacam-macam', 'ditunjukkannya', 'setengah', 'wahai']\n"
     ]
    }
   ],
   "source": [
    "# Spacy sudah support untuk stopwords dalam bahasa indonesia\n",
    "from spacy.lang.id.stop_words import STOP_WORDS\n",
    "\n",
    "# stop words is a set\n",
    "# convert menjadi list\n",
    "print(list(STOP_WORDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- setiap token dalam spacy memiliki attribute is_stop untuk mengecek token tsb apakah sebagai stopword ataukah bukan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berujar True berujar 17470807805421380714\n",
      "menyukai False menyukai 17470807805421380714\n",
      "kekayaan False kekayaan 17470807805421380714\n",
      ". False . 17470807805421380714\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('berujar menyukai kekayaan.')\n",
    "for token in doc:\n",
    "    print(token, token.is_stop, token.lemma_, token.lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ancestors\n",
      "check_flag\n",
      "children\n",
      "cluster\n",
      "conjuncts\n",
      "dep\n",
      "dep_\n",
      "doc\n",
      "ent_id\n",
      "ent_id_\n",
      "ent_iob\n",
      "ent_iob_\n",
      "ent_kb_id\n",
      "ent_kb_id_\n",
      "ent_type\n",
      "ent_type_\n",
      "get_extension\n",
      "has_extension\n",
      "has_vector\n",
      "head\n",
      "i\n",
      "idx\n",
      "is_alpha\n",
      "is_ancestor\n",
      "is_ascii\n",
      "is_bracket\n",
      "is_currency\n",
      "is_digit\n",
      "is_left_punct\n",
      "is_lower\n",
      "is_oov\n",
      "is_punct\n",
      "is_quote\n",
      "is_right_punct\n",
      "is_sent_start\n",
      "is_space\n",
      "is_stop\n",
      "is_title\n",
      "is_upper\n",
      "lang\n",
      "lang_\n",
      "left_edge\n",
      "lefts\n",
      "lemma\n",
      "lemma_\n",
      "lex_id\n",
      "like_email\n",
      "like_num\n",
      "like_url\n",
      "lower\n",
      "lower_\n",
      "morph\n",
      "n_lefts\n",
      "n_rights\n",
      "nbor\n",
      "norm\n",
      "norm_\n",
      "orth\n",
      "orth_\n",
      "pos\n",
      "pos_\n",
      "prefix\n",
      "prefix_\n",
      "prob\n",
      "rank\n",
      "remove_extension\n",
      "right_edge\n",
      "rights\n",
      "sent\n",
      "sent_start\n",
      "sentiment\n",
      "set_extension\n",
      "shape\n",
      "shape_\n",
      "similarity\n",
      "string\n",
      "subtree\n",
      "suffix\n",
      "suffix_\n",
      "tag\n",
      "tag_\n",
      "tensor\n",
      "text\n",
      "text_with_ws\n",
      "vector\n",
      "vector_norm\n",
      "vocab\n",
      "whitespace_\n"
     ]
    }
   ],
   "source": [
    "token = doc[0]\n",
    "attributes = [attr for attr in dir(token) if not attr.startswith('_')]\n",
    "for attr in attributes:\n",
    "    print(attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ORTOGRAFI\n",
    "salah satu atribut yang berguna yaitu attribut2 yang terkait dengan ortografi token seperti :\n",
    "- `is_upper`\n",
    "- `is_lower`\n",
    "- `is_digit`\n",
    "- `is_title`\n",
    "- `is_punct`\n",
    "\n",
    "sesuai denan namanya, stribut2 ini akan mengecek apakah token tsb ditulis dengan huruf kecil, mengandung digit, dll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('HP Samsung Glaxy Note 8 bisa ditebus dengan harga 11 juta rupiah (cashback 1 jt).')\n",
    "str_template = '{:>15} {:>10} {:>10} {:>10} {:>10} {:>10}'\n",
    "print(str_template.format('token', 'is_lower', 'is_title', 'is_upper', 'is_digit', 'is_punct'))\n",
    "for token in doc:\n",
    "    print(str_template.format(str(token),\n",
    "                              str(token.is_lower),\n",
    "                              str(token.is_title),\n",
    "                              str(token.is_upper),\n",
    "                              str(token.is_digit),\n",
    "                              str(token.is_punct),\n",
    "#                               str(token.is_stop),\n",
    "                             ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEMMA\n",
    "lemma atau bentuk dasar suatu kata dapat kita peroleh menggunakan spacy.\n",
    "terdapat satu dictionary besar di `spacy.lang.id.LOOKUP`, dengan `key` merupakan kata dan `value` adalah bentuk lemmanya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy.lang.id\n",
    "from spacy_lookup import Entity\n",
    "nlp = spacy.blank('id')\n",
    "entity = Entity(keywords_list=['python', 'java platform'])\n",
    "nlp.add_pipe(entity, last=True)\n",
    "\n",
    "from spacy.lang.id import ID\n",
    "lemmatizer = ID.Defaults.create_lemmatizer()\n",
    "lemmatizer\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
